{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61248eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # ÂÖ®ÈÉ®Â∞èÂÜô\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # ÁßªÈô§ÈìæÊé•\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)           # ÁßªÈô§ HTML Ê†áÁ≠æ\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)        # Âè™‰øùÁïôËã±ÊñáÂ≠óÊØçÂíåÁ©∫Ê†º\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()    # Â§ö‰ΩôÁ©∫Ê†ºÂêàÂπ∂\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f7e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('MBTI_500.csv')\n",
    "df['clean_posts'] = df['posts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96747fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF ÂêëÈáèÂåñÊñáÊú¨\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X_tfidf = TfidfVectorizer().fit_transform(df['clean_posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24b6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê†áÁ≠æÁºñÁ†Å\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['type'])  # Â∞Ü 16 ‰∏™ MBTI Á±ªÂûãËΩ¨‰∏∫ 0-15 ÁöÑÊï¥Êï∞Ê†áÁ≠æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac0e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ÂàíÂàÜÊï∞ÊçÆÈõÜ\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26cab536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Logistic Regression Accuracy: 0.8302536061091732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.68      0.78      0.73       319\n",
      "        ENFP       0.77      0.84      0.80      1249\n",
      "        ENTJ       0.75      0.88      0.81       577\n",
      "        ENTP       0.84      0.83      0.84      2324\n",
      "        ESFJ       0.59      0.70      0.64        33\n",
      "        ESFP       0.64      0.69      0.67        75\n",
      "        ESTJ       0.82      0.90      0.86       105\n",
      "        ESTP       0.84      0.93      0.88       398\n",
      "        INFJ       0.85      0.80      0.83      2954\n",
      "        INFP       0.80      0.82      0.81      2391\n",
      "        INTJ       0.87      0.83      0.85      4531\n",
      "        INTP       0.89      0.83      0.86      5033\n",
      "        ISFJ       0.55      0.81      0.65       132\n",
      "        ISFP       0.53      0.78      0.63       161\n",
      "        ISTJ       0.56      0.85      0.68       253\n",
      "        ISTP       0.79      0.87      0.83       679\n",
      "\n",
      "    accuracy                           0.83     21214\n",
      "   macro avg       0.74      0.82      0.77     21214\n",
      "weighted avg       0.84      0.83      0.83     21214\n",
      "\n",
      "üîπ Random Forest Accuracy: 0.5223437352691619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00       319\n",
      "        ENFP       0.84      0.10      0.18      1249\n",
      "        ENTJ       1.00      0.16      0.28       577\n",
      "        ENTP       0.78      0.24      0.36      2324\n",
      "        ESFJ       0.00      0.00      0.00        33\n",
      "        ESFP       0.00      0.00      0.00        75\n",
      "        ESTJ       0.92      0.69      0.79       105\n",
      "        ESTP       0.92      0.66      0.77       398\n",
      "        INFJ       0.56      0.56      0.56      2954\n",
      "        INFP       0.77      0.33      0.46      2391\n",
      "        INTJ       0.53      0.70      0.60      4531\n",
      "        INTP       0.44      0.87      0.58      5033\n",
      "        ISFJ       0.00      0.00      0.00       132\n",
      "        ISFP       0.00      0.00      0.00       161\n",
      "        ISTJ       0.00      0.00      0.00       253\n",
      "        ISTP       0.94      0.02      0.04       679\n",
      "\n",
      "    accuracy                           0.52     21214\n",
      "   macro avg       0.48      0.27      0.29     21214\n",
      "weighted avg       0.60      0.52      0.47     21214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuxinsugar/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shuxinsugar/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shuxinsugar/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ËÆ≠ÁªÉÊ®°Âûã + ËØÑ‰º∞ÔºàLR Âíå RFÔºâ\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "\n",
    "print(\"üîπ Logistic Regression Accuracy:\", accuracy_score(y_val, y_pred_lr))\n",
    "print(classification_report(y_val, y_pred_lr, target_names=le.classes_))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "\n",
    "print(\"üîπ Random Forest Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
    "print(classification_report(y_val, y_pred_rf, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
