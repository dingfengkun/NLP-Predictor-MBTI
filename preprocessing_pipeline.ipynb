{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd56b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3008a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dataset with 1794016 rows in 6.87s\n",
      "‚ùå Removed invalid MBTI: 137091 rows in 1.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/kc41xjcj09n731lz40b9xg6c0000gn/T/ipykernel_37592/114955857.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df['body'].str.upper().str.contains(mbti_pattern)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Removed posts mentioning MBTI: 276907 rows in 15.09s\n",
      "‚ùå Removed empty posts: 16 rows in 0.75s\n",
      "‚ùå Removed short posts (< 10 words): 330251 rows in 3.81s\n",
      "‚ùå Removed duplicates: 2262 rows in 0.39s\n",
      "‚úÖ Normalized post text in 1.06s\n",
      "\n",
      "üìä Final Summary:\n",
      "‚úÖ Final cleaned dataset has 1047489 rows\n",
      "‚è±Ô∏è Total preprocessing time: 30.18s\n"
     ]
    }
   ],
   "source": [
    "# --- Start total timer ---\n",
    "start_total = time.time()\n",
    "\n",
    "# --- Load data ---\n",
    "start = time.time()\n",
    "df = pd.read_csv('mbti_full_pull.csv')  # ‚¨ÖÔ∏è Replace with actual path\n",
    "original_count = len(df)\n",
    "print(f\"‚úÖ Loaded dataset with {original_count} rows in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Define MBTI types and pattern ---\n",
    "mbti_types = [\n",
    "    'INTJ', 'INTP', 'ENTJ', 'ENTP',\n",
    "    'INFJ', 'INFP', 'ENFJ', 'ENFP',\n",
    "    'ISTJ', 'ISFJ', 'ESTJ', 'ESFJ',\n",
    "    'ISTP', 'ISFP', 'ESTP', 'ESFP'\n",
    "]\n",
    "mbti_pattern = r'\\b(' + '|'.join(mbti_types) + r')\\b'\n",
    "\n",
    "# --- Step 1: Extract MBTI from flair ---\n",
    "start = time.time()\n",
    "def extract_mbti(text):\n",
    "    match = re.findall(mbti_pattern, str(text).upper())\n",
    "    return match[0] if match else None\n",
    "\n",
    "df['MBTI'] = df['author_flair_text'].apply(extract_mbti)\n",
    "before_mbti_filter = len(df)\n",
    "df = df.dropna(subset=['MBTI'])\n",
    "removed_no_mbti = before_mbti_filter - len(df)\n",
    "print(f\"‚ùå Removed invalid MBTI: {removed_no_mbti} rows in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Step 2: Remove posts with MBTI mentions ---\n",
    "start = time.time()\n",
    "df['body'] = df['body'].astype(str)\n",
    "before_mbti_in_post = len(df)\n",
    "df = df[~df['body'].str.upper().str.contains(mbti_pattern)]\n",
    "removed_mbti_mentions = before_mbti_in_post - len(df)\n",
    "print(f\"‚ùå Removed posts mentioning MBTI: {removed_mbti_mentions} rows in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Step 3: Remove empty posts ---\n",
    "start = time.time()\n",
    "before_empty = len(df)\n",
    "df = df[df['body'].str.strip() != '']\n",
    "removed_empty = before_empty - len(df)\n",
    "print(f\"‚ùå Removed empty posts: {removed_empty} rows in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Step 4: Remove short posts ---\n",
    "start = time.time()\n",
    "df['word_count'] = df['body'].apply(lambda x: len(x.strip().split()))\n",
    "min_words = 10\n",
    "before_short = len(df)\n",
    "df = df[df['word_count'] >= min_words]\n",
    "removed_short = before_short - len(df)\n",
    "print(f\"‚ùå Removed short posts (< {min_words} words): {removed_short} rows in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Step 5: Remove duplicates ---\n",
    "start = time.time()\n",
    "before_duplicates = len(df)\n",
    "df = df.drop_duplicates(subset='body')\n",
    "removed_duplicates = before_duplicates - len(df)\n",
    "print(f\"‚ùå Removed duplicates: {removed_duplicates} rows in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Step 6: Normalize post text ---\n",
    "start = time.time()\n",
    "df['POST'] = df['body'].str.lower().str.strip()\n",
    "print(f\"‚úÖ Normalized post text in {time.time() - start:.2f}s\")\n",
    "\n",
    "# --- Final cleanup ---\n",
    "df_cleaned = df[['MBTI', 'POST']].reset_index(drop=True)\n",
    "\n",
    "# --- Total summary ---\n",
    "end_total = time.time()\n",
    "print(\"\\nüìä Final Summary:\")\n",
    "print(f\"‚úÖ Final cleaned dataset has {len(df_cleaned)} rows\")\n",
    "print(f\"‚è±Ô∏è Total preprocessing time: {end_total - start_total:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e20bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
